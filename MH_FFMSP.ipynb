{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristics for FFMSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 1 2 1 0 1 1 2 1 0 3 0 1 3 2 2 3 2 3 2 2 3 2 0 2 3 0 3 0 0 3 3 2 2 0\n",
      " 0 3 0 0 1 1 3 2 2 2 3 3 3 0 2 2 0 0 1 1 1 0 2 2 2 3 1 0 1 0 0 3 1 2 3 3 1\n",
      " 0 0 1 1 2 1 0 0 1 1 1 1 3 2 2 0 3 2 2 2 3 0 3 2 1 1]\n",
      "[24 28 30 25 26 25 28 26 23 27 23 26 20 24 27 22 26 35 27 26 27 31 24 28\n",
      " 27 18 21 29 24 30 20 25 21 26 30 28 24 24 30 24 28 32 22 24 27 29 29 25\n",
      " 32 19 20 28 20 24 29 24 30 19 18 22 28 31 19 29 34 28 31 30 28 26 23 24\n",
      " 19 28 31 22 21 33 25 30 25 17 23 32 26 26 22 25 31 26 21 33 26 25 23 23\n",
      " 24 26 24 24 17 31 28 24 22 23 21 24 29 26 31 26 26 23 24 23 20 33 20 28\n",
      " 23 22 26 26 34 25 31 29 29 31 27 31 28 24 20 27 31 25 24 29 32 19 31 26\n",
      " 18 25 28 24 20 18 25 25 30 27 23 25 22 26 23 25 23 30 24 25 23 24 15 32\n",
      " 22 16 24 19 25 26 25 20 23 28 25 26 22 21 26 26 25 26 20 34 25 33 26 30\n",
      " 31 28 22 23 25 29 25 23 22 22 27 26 29 27 34 25 25 27 33 25 23 22 24 30\n",
      " 23 27 27 28 26 25 21 30 18 25 31 24 28 18 36 25 21 16 20 30 24 24 28 27\n",
      " 25 20 23 24 18 22 14 32 25 29 24 30 24 22 32 28 25 16 22 21 31 18 28 22\n",
      " 20 26 24 21 26 30 21 21 23 28 24 23 23 33 23 26 27 22 23 21 20 31 21 24\n",
      " 20 22 28 25 21 28 25 26 27 28 31 30]\n"
     ]
    }
   ],
   "source": [
    "filename = \"problem_instances/100-300-001.txt\"\n",
    "data = []\n",
    "mapper = {'A':0, 'C':1, 'T':2, 'G':3} #char to int\n",
    "rev_mapper = {0:'A', 1:'C' , 2:'T', 3:'G'} #int to char, whenever needed\n",
    "alphabet = (0,1,2,3)\n",
    "# read per char, for matrix data structure, while mapping ['A', 'C', 'T', 'G'] to [0,1,2,3] at the same time:\n",
    "with open(filename) as fileobj:\n",
    "    for line in fileobj:\n",
    "        d = []\n",
    "        line = line.rstrip(\"\\n\")\n",
    "        for ch in line:\n",
    "            mapch = mapper[ch]\n",
    "            d.append(mapch)\n",
    "        data.append(d)\n",
    "n = len(data); m = len(data[0])\n",
    "data = np.array(data)\n",
    "#count = np.char.count(data[0], 'A')\n",
    "count = np.count_nonzero(data == mapper['A'], axis=0)\n",
    "\n",
    "print(data[:,0])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffmsp_obj(sol, data, threshold):\n",
    "    '''objective function of the FFMSP:\n",
    "    computes the hamming distance of the solution and each solution in the data,\n",
    "    if the count of hamming distances of sol and one sol from data >= t, then add 1 cardinality.\n",
    "    \n",
    "    returns: objective function value, scalar.\n",
    "    params:\n",
    "        - sol, vector of solution of FFMSP, shape = m\n",
    "        - data, matrix containing list of strings, shape = (n, m)\n",
    "        - threshold, [0, m], scalar.\n",
    "    '''\n",
    "    # init vars:\n",
    "    n = data.shape[0]; m = data.shape[1]\n",
    "    y = 0\n",
    "    \n",
    "    # compute the hamming distance of one cell of sol to all in data:\n",
    "    hamming_array = np.not_equal(sol, data) # contains matrix of predicate function\n",
    "    #print(hamming_array)\n",
    "    for i in range(n):\n",
    "        count_hamming = 1 if np.sum(hamming_array[i]) >= threshold else 0\n",
    "        y += count_hamming\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = np.array([0,1,3,3])\n",
    "dat = np.array([\n",
    "                [0, 1, 3, 3],\n",
    "                [0, 2, 0, 2],\n",
    "                [3, 1, 3, 0],\n",
    "                [0,2,3,3]\n",
    "                ])\n",
    "ffmsp_obj(sol, dat, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(data, alphabet, t):\n",
    "    '''\n",
    "    the simple greedy algo for FFMSP uses a consensus of each column (string position): \n",
    "    takes the char with the least occurence from all strings on each position - maximization problem. \n",
    "    \n",
    "    returns:\n",
    "        - solution vector, shape = m\n",
    "        - objective function, scalar\n",
    "    params:\n",
    "        - data, matrix containing list of strings, shape = (n, m)\n",
    "        - alphabet, vector (mathematically, a set), shape = len(alphabet)\n",
    "        - threshold t, scalar\n",
    "    '''\n",
    "    n = data.shape[0]; m = data.shape[1]; alpha_size = len(alphabet)\n",
    "    threshold = int(t*m) # since t is in percentage\n",
    "    freq_mat = np.zeros((alpha_size, m))\n",
    "    # count the occurences of each alphabet column wise:\n",
    "    for i in range(alpha_size):\n",
    "        freq_mat[i] = np.count_nonzero(data == alphabet[i], axis = 0) # alphabet[i] == i in this case, can use whichever\n",
    "    \n",
    "    #print(freq_mat)\n",
    "    sol = np.argmin(freq_mat, axis=0) # get char with lowest frequency for each position [0, m]\n",
    "    f = ffmsp_obj(sol, data, threshold) # compute obj fun\n",
    "    return sol, f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 3 3]\n",
      " [0 2 0 2]\n",
      " [3 1 3 0]\n",
      " [0 2 3 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 1]), 4)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dat)\n",
    "greedy(dat, alphabet, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 3, 3, 0, 1, 2, 1, 1, 1, 1,\n",
       "        2, 2, 2, 0, 3, 3, 2, 2, 0, 1, 2, 3, 2, 1, 1, 2, 1, 3, 3, 1, 3, 3,\n",
       "        2, 3, 1, 3, 3, 0, 0, 3, 0, 3, 1, 1, 2, 0, 0, 3, 1, 3, 0, 2, 2, 3,\n",
       "        3, 2, 1, 1, 1, 0, 0, 2, 3, 0, 0, 1, 1, 3, 3, 0, 3, 3, 1, 1, 1, 3,\n",
       "        2, 2, 0, 1, 3, 1, 3, 2, 2, 2, 2, 3, 0, 1, 3, 0, 0, 0, 2, 2, 1, 2,\n",
       "        2, 2, 3, 2, 3, 1, 0, 1, 0, 2, 1, 0, 1, 3, 3, 3, 2, 2, 2, 2, 2, 3,\n",
       "        3, 0, 0, 3, 3, 1, 2, 3, 3, 0, 2, 3, 0, 2, 3, 2, 0, 0, 1, 3, 2, 3,\n",
       "        3, 3, 1, 3, 1, 2, 2, 2, 0, 2, 1, 3, 0, 1, 0, 0, 3, 0, 2, 2, 1, 0,\n",
       "        2, 3, 3, 2, 0, 0, 2, 1, 2, 1, 0, 1, 3, 3, 1, 2, 3, 2, 3, 3, 3, 2,\n",
       "        3, 1, 0, 1, 2, 3, 1, 1, 2, 2, 3, 3, 3, 2, 0, 2, 2, 1, 3, 2, 2, 2,\n",
       "        1, 3, 0, 2, 0, 3, 1, 2, 3, 0, 3, 3, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0,\n",
       "        1, 3, 0, 3, 0, 3, 3, 1, 2, 1, 1, 2, 1, 1, 2, 0, 3, 0, 1, 0, 1, 0,\n",
       "        0, 2, 1, 0, 2, 1, 1, 0, 3, 1, 2, 0, 0, 2, 1, 1, 3, 0, 0, 0, 0, 3,\n",
       "        0, 1, 0, 2, 3, 2, 0, 1, 3, 2, 3, 1, 3, 1]),\n",
       " 0)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy(data, alphabet, 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_search(data, alphabet, t, init='greedy', sol=None):\n",
    "    '''\n",
    "    simple local search, by flipping each cell and only accepting solution(s) that are better\n",
    "    pretty much gradient descent but FFMSP ver.\n",
    "    \n",
    "    returns the same params and takes in the same params as greedy algo except:\n",
    "    params:\n",
    "        - init, decides initialization mode, string\n",
    "        - sol, starting solution, will use this instead of init if this is not empty, shape = m\n",
    "    '''\n",
    "    # init var:\n",
    "    n = data.shape[0]; m = data.shape[1]; alpha_size = len(alphabet)\n",
    "    threshold = int(t*m) # for obj fun\n",
    "    f=0\n",
    "    \n",
    "    # generate init sol:\n",
    "    if sol is not None:\n",
    "        f = ffmsp_obj(sol, data, threshold)\n",
    "    else:\n",
    "        if init == \"greedy\":\n",
    "            sol, f = greedy(data, alphabet, t)\n",
    "        elif init == \"random\":\n",
    "            sol = np.random.randint(alpha_size, size=m)\n",
    "            f = ffmsp_obj(sol, data, threshold)\n",
    "    \n",
    "    # do local search, flip each bit position:\n",
    "    for i in range(m):\n",
    "        for j in range(alpha_size):\n",
    "            if sol[i] != alphabet[j]: # exclude current char\n",
    "                # implicitly flip bit, check if better - if yes then stop and check next pos:\n",
    "                sol_new = np.copy(sol) # need to copy since numpy by default refers to memory instead. Need to replace with more eficient op\n",
    "                sol_new[i] = j\n",
    "                f_new = ffmsp_obj(sol_new, data, threshold)\n",
    "                #print(sol_new, f_new)\n",
    "                #print(sol, f, i, j, sol_new, f_new)\n",
    "                if f_new >= f:\n",
    "                    sol = sol_new; f = f_new\n",
    "                    #print(\"should break here!\")\n",
    "                    #break # without break seems better\n",
    "    return sol, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 3 3]\n",
      " [0 2 0 2]\n",
      " [3 1 3 0]\n",
      " [0 2 3 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 3, 3]), 4)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dat)\n",
    "local_search(dat, alphabet, 0.5, init='greedy', sol = np.array([2,2,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 3, 1, 2, 3, 3, 3, 1, 3, 3, 1, 3, 3, 2, 0, 3, 1, 3, 3, 1,\n",
       "        2, 2, 2, 0, 3, 1, 2, 2, 0, 1, 2, 3, 2, 1, 1, 2, 1, 3, 3, 1, 3, 3,\n",
       "        2, 3, 1, 3, 3, 0, 0, 3, 2, 3, 1, 1, 2, 0, 0, 3, 1, 3, 0, 2, 2, 3,\n",
       "        3, 3, 1, 1, 3, 1, 0, 2, 3, 0, 0, 1, 1, 3, 3, 0, 3, 3, 1, 1, 1, 3,\n",
       "        2, 2, 3, 1, 3, 1, 3, 2, 2, 2, 2, 1, 0, 1, 3, 0, 0, 0, 2, 2, 3, 2,\n",
       "        2, 2, 3, 2, 3, 1, 0, 1, 0, 2, 1, 0, 1, 3, 3, 3, 2, 2, 2, 2, 2, 3,\n",
       "        3, 0, 0, 3, 3, 1, 2, 3, 3, 0, 2, 3, 0, 2, 3, 2, 0, 0, 1, 3, 2, 3,\n",
       "        3, 3, 1, 3, 1, 2, 2, 2, 0, 2, 1, 3, 0, 1, 0, 0, 3, 0, 2, 2, 1, 0,\n",
       "        2, 3, 3, 2, 0, 0, 2, 1, 2, 1, 0, 1, 3, 3, 1, 2, 3, 2, 3, 3, 3, 2,\n",
       "        3, 1, 0, 1, 2, 3, 1, 1, 2, 2, 3, 3, 3, 2, 0, 2, 2, 1, 3, 2, 2, 2,\n",
       "        1, 3, 0, 2, 0, 3, 1, 2, 3, 0, 3, 3, 0, 0, 1, 2, 2, 1, 1, 2, 2, 0,\n",
       "        1, 3, 0, 3, 0, 3, 3, 1, 2, 1, 1, 2, 1, 1, 2, 0, 3, 0, 1, 1, 1, 0,\n",
       "        1, 2, 1, 0, 2, 1, 1, 0, 3, 1, 2, 0, 0, 2, 1, 1, 3, 0, 0, 0, 0, 3,\n",
       "        0, 3, 0, 2, 3, 2, 0, 1, 3, 2, 3, 3, 3, 1]),\n",
       " 67)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_search(data, alphabet, 0.8, init='greedy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metaheuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaheuristic(data, alphabet, t, max_loop, rand, init=\"greedy\"):\n",
    "    '''\n",
    "    simple idea: to avoid local minima, use perturbation - randomly swapping cells with random letters, where the random percentage is a tuning parameter  \n",
    "    returns the same params as the greedy algo.\n",
    "    params, same as prev methods, except:\n",
    "        - max_loop, hyperparameter determining maximum perturbation+local search ops, int scalar\n",
    "        - rand, a hyperparameter [0,1] percentage of the mutated cells, lower means faster convergence, real scalar \n",
    "            -> seems like near 0 is a good choice\n",
    "            -> rand doesnt give any effect! maybe because of the local search is less strict\n",
    "    '''\n",
    "     # init var:\n",
    "    n = data.shape[0]; m = data.shape[1]; alpha_size = len(alphabet)\n",
    "    threshold = int(t*m) # for obj fun\n",
    "    f=0\n",
    "    \n",
    "    # generate init sol:\n",
    "    if init == \"greedy\":\n",
    "        sol, f = greedy(data, alphabet, t)\n",
    "    elif init == \"random\":\n",
    "        sol = np.random.randint(alpha_size, size=m)\n",
    "        f = ffmsp_obj(sol, data, threshold)\n",
    "        \n",
    "    # loop the local search and perturbation:\n",
    "    i = 0\n",
    "    perturb_length = int(rand*m)\n",
    "    print(perturb_length)\n",
    "    # do initial local search for the lower bound:\n",
    "    sol, f = local_search(data, alphabet, t, sol=sol)\n",
    "    while i<max_loop:\n",
    "        # perturb sol, generate random integer array [0,alpha_size] with length = perturb_length which replaces random cells:\n",
    "        part_sol = np.random.randint(alpha_size, size=perturb_length)\n",
    "        idx = np.random.randint(m, size=perturb_length) # replacement indexes\n",
    "        #print(part_sol, idx)\n",
    "        sol_perturb = np.copy(sol) # i wonder if there's another way than just copying, seem heavy\n",
    "        sol_perturb[idx] = part_sol # replace some sol components wiwth the part_sol\n",
    "        #print(sol_perturb)\n",
    "        # do local search:\n",
    "        sol_new, f_new = local_search(data, alphabet, t, sol=sol_perturb)\n",
    "        \n",
    "        #sort of greedy acceptante criteria, compare with previous local minimum:\n",
    "        if f_new >= f:\n",
    "            sol = sol_new\n",
    "            f = f_new\n",
    "            print(i,\"accepted\",f)\n",
    "        i+=1\n",
    "    return sol, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 accepted 67\n",
      "1 accepted 68\n",
      "2 accepted 68\n",
      "3 accepted 68\n",
      "4 accepted 68\n",
      "5 accepted 68\n",
      "6 accepted 68\n",
      "7 accepted 68\n",
      "8 accepted 68\n",
      "9 accepted 68\n",
      "10 accepted 68\n",
      "11 accepted 68\n",
      "12 accepted 68\n",
      "13 accepted 68\n",
      "14 accepted 68\n",
      "15 accepted 68\n",
      "16 accepted 68\n",
      "17 accepted 68\n",
      "18 accepted 68\n",
      "19 accepted 68\n",
      "20 accepted 68\n",
      "21 accepted 68\n",
      "22 accepted 68\n",
      "23 accepted 68\n",
      "24 accepted 68\n",
      "25 accepted 68\n",
      "26 accepted 68\n",
      "27 accepted 68\n",
      "28 accepted 68\n",
      "29 accepted 68\n",
      "30 accepted 68\n",
      "31 accepted 68\n",
      "32 accepted 68\n",
      "33 accepted 68\n",
      "34 accepted 68\n",
      "35 accepted 68\n",
      "36 accepted 68\n",
      "37 accepted 68\n",
      "38 accepted 68\n",
      "39 accepted 68\n",
      "40 accepted 68\n",
      "41 accepted 68\n",
      "42 accepted 68\n",
      "43 accepted 68\n",
      "44 accepted 68\n",
      "45 accepted 68\n",
      "46 accepted 68\n",
      "47 accepted 68\n",
      "48 accepted 68\n",
      "49 accepted 68\n",
      "50 accepted 68\n",
      "51 accepted 68\n",
      "52 accepted 68\n",
      "53 accepted 68\n",
      "54 accepted 68\n",
      "55 accepted 68\n",
      "56 accepted 68\n",
      "57 accepted 68\n",
      "58 accepted 68\n",
      "59 accepted 68\n",
      "60 accepted 68\n",
      "61 accepted 68\n",
      "62 accepted 68\n",
      "63 accepted 68\n",
      "64 accepted 68\n",
      "65 accepted 68\n",
      "66 accepted 68\n",
      "67 accepted 68\n",
      "68 accepted 68\n",
      "69 accepted 68\n",
      "70 accepted 68\n",
      "71 accepted 68\n",
      "72 accepted 68\n",
      "73 accepted 68\n",
      "74 accepted 68\n",
      "75 accepted 68\n",
      "76 accepted 68\n",
      "77 accepted 68\n",
      "78 accepted 68\n",
      "79 accepted 68\n",
      "80 accepted 68\n",
      "81 accepted 68\n",
      "82 accepted 68\n",
      "83 accepted 68\n",
      "84 accepted 68\n",
      "85 accepted 68\n",
      "86 accepted 68\n",
      "87 accepted 68\n",
      "88 accepted 68\n",
      "89 accepted 68\n",
      "90 accepted 68\n",
      "91 accepted 68\n",
      "92 accepted 68\n",
      "93 accepted 68\n",
      "94 accepted 68\n",
      "95 accepted 68\n",
      "96 accepted 68\n",
      "97 accepted 68\n",
      "98 accepted 68\n",
      "99 accepted 68\n",
      "100 accepted 68\n",
      "101 accepted 68\n",
      "102 accepted 68\n",
      "103 accepted 68\n",
      "104 accepted 68\n",
      "105 accepted 68\n",
      "106 accepted 68\n",
      "107 accepted 68\n",
      "108 accepted 68\n",
      "109 accepted 68\n",
      "110 accepted 68\n",
      "111 accepted 68\n",
      "112 accepted 68\n",
      "113 accepted 68\n",
      "114 accepted 68\n",
      "115 accepted 68\n",
      "116 accepted 68\n",
      "117 accepted 68\n",
      "118 accepted 68\n",
      "119 accepted 68\n",
      "120 accepted 68\n",
      "121 accepted 68\n",
      "122 accepted 68\n",
      "123 accepted 68\n",
      "124 accepted 68\n",
      "125 accepted 68\n",
      "126 accepted 68\n",
      "127 accepted 68\n",
      "128 accepted 68\n",
      "129 accepted 68\n",
      "130 accepted 68\n",
      "131 accepted 68\n",
      "132 accepted 68\n",
      "133 accepted 68\n",
      "134 accepted 68\n",
      "135 accepted 68\n",
      "136 accepted 68\n",
      "137 accepted 68\n",
      "138 accepted 68\n",
      "139 accepted 68\n",
      "140 accepted 68\n",
      "141 accepted 68\n",
      "142 accepted 68\n",
      "143 accepted 68\n",
      "144 accepted 68\n",
      "145 accepted 68\n",
      "146 accepted 68\n",
      "147 accepted 68\n",
      "148 accepted 68\n",
      "149 accepted 68\n",
      "150 accepted 68\n",
      "151 accepted 68\n",
      "152 accepted 68\n",
      "153 accepted 68\n",
      "154 accepted 68\n",
      "155 accepted 68\n",
      "156 accepted 68\n",
      "157 accepted 68\n",
      "158 accepted 68\n",
      "159 accepted 68\n",
      "160 accepted 68\n",
      "161 accepted 68\n",
      "162 accepted 68\n",
      "163 accepted 68\n",
      "164 accepted 68\n",
      "165 accepted 68\n",
      "166 accepted 68\n",
      "167 accepted 68\n",
      "168 accepted 68\n",
      "169 accepted 68\n",
      "170 accepted 68\n",
      "171 accepted 68\n",
      "172 accepted 68\n",
      "173 accepted 68\n",
      "174 accepted 68\n",
      "175 accepted 68\n",
      "176 accepted 68\n",
      "177 accepted 68\n",
      "178 accepted 68\n",
      "179 accepted 68\n",
      "180 accepted 68\n",
      "181 accepted 68\n",
      "182 accepted 68\n",
      "183 accepted 68\n",
      "184 accepted 68\n",
      "185 accepted 68\n",
      "186 accepted 68\n",
      "187 accepted 68\n",
      "188 accepted 68\n",
      "189 accepted 68\n",
      "190 accepted 68\n",
      "191 accepted 68\n",
      "192 accepted 68\n",
      "193 accepted 68\n",
      "194 accepted 68\n",
      "195 accepted 68\n",
      "196 accepted 68\n",
      "197 accepted 68\n",
      "198 accepted 68\n",
      "199 accepted 68\n",
      "200 accepted 68\n",
      "201 accepted 68\n",
      "202 accepted 68\n",
      "203 accepted 68\n",
      "204 accepted 68\n",
      "205 accepted 68\n",
      "206 accepted 68\n",
      "207 accepted 68\n",
      "208 accepted 68\n",
      "209 accepted 68\n",
      "210 accepted 68\n",
      "211 accepted 68\n",
      "212 accepted 68\n",
      "213 accepted 68\n",
      "214 accepted 68\n",
      "215 accepted 68\n",
      "216 accepted 68\n",
      "217 accepted 68\n",
      "218 accepted 68\n",
      "219 accepted 68\n",
      "220 accepted 68\n",
      "221 accepted 68\n",
      "222 accepted 68\n",
      "223 accepted 68\n",
      "224 accepted 68\n",
      "225 accepted 68\n",
      "226 accepted 68\n",
      "227 accepted 68\n",
      "228 accepted 68\n",
      "229 accepted 68\n",
      "230 accepted 68\n",
      "231 accepted 68\n",
      "232 accepted 68\n",
      "233 accepted 68\n",
      "234 accepted 68\n",
      "235 accepted 68\n",
      "236 accepted 68\n",
      "237 accepted 68\n",
      "238 accepted 68\n",
      "239 accepted 68\n",
      "240 accepted 68\n",
      "241 accepted 68\n",
      "242 accepted 68\n",
      "243 accepted 68\n",
      "244 accepted 68\n",
      "245 accepted 68\n",
      "246 accepted 68\n",
      "247 accepted 68\n",
      "248 accepted 68\n",
      "249 accepted 68\n",
      "250 accepted 68\n",
      "251 accepted 68\n",
      "252 accepted 68\n",
      "253 accepted 68\n",
      "254 accepted 68\n",
      "255 accepted 68\n",
      "256 accepted 68\n",
      "257 accepted 68\n",
      "258 accepted 68\n",
      "259 accepted 68\n",
      "260 accepted 68\n",
      "261 accepted 68\n",
      "262 accepted 68\n",
      "263 accepted 68\n",
      "264 accepted 68\n",
      "265 accepted 68\n",
      "266 accepted 68\n",
      "267 accepted 68\n",
      "268 accepted 68\n",
      "269 accepted 68\n",
      "270 accepted 68\n",
      "271 accepted 68\n",
      "272 accepted 68\n",
      "273 accepted 68\n",
      "274 accepted 68\n",
      "275 accepted 68\n",
      "276 accepted 68\n",
      "277 accepted 68\n",
      "278 accepted 68\n",
      "279 accepted 68\n",
      "280 accepted 68\n",
      "281 accepted 68\n",
      "282 accepted 68\n",
      "283 accepted 68\n",
      "284 accepted 68\n",
      "285 accepted 68\n",
      "286 accepted 68\n",
      "287 accepted 68\n",
      "288 accepted 68\n",
      "289 accepted 68\n",
      "290 accepted 68\n",
      "291 accepted 68\n",
      "292 accepted 68\n",
      "293 accepted 68\n",
      "294 accepted 68\n",
      "295 accepted 68\n",
      "296 accepted 68\n",
      "297 accepted 68\n",
      "298 accepted 68\n",
      "299 accepted 68\n",
      "300 accepted 68\n",
      "301 accepted 68\n",
      "302 accepted 68\n",
      "303 accepted 68\n",
      "304 accepted 68\n",
      "305 accepted 68\n",
      "306 accepted 68\n",
      "307 accepted 68\n",
      "308 accepted 68\n",
      "309 accepted 68\n",
      "310 accepted 68\n",
      "311 accepted 68\n",
      "312 accepted 68\n",
      "313 accepted 68\n",
      "314 accepted 68\n",
      "315 accepted 68\n",
      "316 accepted 68\n",
      "317 accepted 68\n",
      "318 accepted 68\n",
      "319 accepted 68\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "metaheuristic(data, alphabet, 0.8, 500, 1e-3, init=\"greedy\")\n",
    "elapsed = time.time()-start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with genetic algo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
